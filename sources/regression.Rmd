---
title: Régression linéaire 
subtitle: simple et multiple
author: Marie-Pierre Etienne
date: '2020/09/11 (updated: `r Sys.Date()`)'
institute: https://github.com/marieetienne
csl: ../resources/apa-no-doi-no-issue.csl
output:
  xaringan::moon_reader:
    css: [  'metropolis',  'mpe_pres.css']
    lib_dir: libs
    nature:
      ratio: 16:10
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: '../resources/collapseoutput.js'
    includes:
      after_body: '../resources/insert-logo.html'
fontsize: 10pt
params:
  child_path: ''
  setup_path: ../resources/
---



```{r setup, include=FALSE, eval = TRUE}
source(paste0(params$setup_path, "knitr_setup.R"))
with_sol <- TRUE ## in order to control the output
with_course <- TRUE
library('flipbookr')
library(RefManageR)
library(tidyverse)
library(ggplot2)
```

```{r xaringanExtra-share-again, echo=FALSE}
xaringanExtra::use_share_again()
```

```{r reference,  include=FALSE, cache=FALSE, eval = TRUE}
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "alphabetic",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("./lm.bib", check = FALSE)
```


name: intro
# Introduction

---
template: intro
## Etude de la pollution au SO2

On a mesuré pour 41 villes américaines, la pollution au SO2 ainsi que la population dans la ville

```{r datapackage, eval = TRUE, echo = FALSE, warning = FALSE}
ggplot <- function(...) ggplot2::ggplot(...) + scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) 
#remotes::install_github('MarieEtienne/coursesdata', force = TRUE)
```

```{r usfata, eval = TRUE, echo = c(1,2), warning = FALSE}
library(coursesdata)
data(usdata)
usdata %>% ggplot() +  aes(x= pop, y = SO2)+  geom_point()
```


--
<p class="question"> La taille d'une ville est elle liée à la pollution en SO2 ?</p>


---
template: intro
## Cadre général du modèle de régression simple

On étudie le lien entre  
- une variable quantitative notée $Y$ (l'indicateur de SO2),
- et une variable quantitative $x$.

Les données peuvent être visualisées à l'aide d'un nuage de points.


--
<p class="question"> La variable x permet elle d'expliquer la variabilité de la variable Y ?</p>

---
name: model
# Le modèle de régression simple

---
template: model

## Graphiquement 

Une visualisation graphique du modèle d'analyse de régression simple

<br> <br> <br> <br>


Comment imagine-t-on le processus aléatoire qui a conduit à nos données ?




---

```{r reg_versiongraphique_prep, eval = TRUE, echo = FALSE}
set.seed(222)
n <- 20
x <- round(rnorm(n, mean= 10, sd = 2),2)
beta0 <- 1
beta1 <- 0.5
sigma <- 1
fake_dta <- tibble(x= x, y = rnorm(n, mean = beta0 + beta1*x, sd =sigma))  

x0 <-  x[4]
norm_dta <- tibble::tibble(y = rnorm(1000, mean=beta0 + beta1*x0, sd= sigma), x= x0 + dnorm(x = y- beta0 - beta1*x0, mean= 0,  sd=0.5))

norm_dta0 <- tibble::tibble(y = rnorm(1000, mean=mean(fake_dta$y), sd= sigma), x= x0 + dnorm(x = y - mean(fake_dta$y), mean= 0,  sd=0.5))
```


```{r reg_versiongraphique}
ggplot(data=fake_dta) + 
  ylab('y') + xlim(range(fake_dta$x)) +ylim(range(fake_dta$y)) +
  ggtitle('Modèle Mcomp') +
  geom_abline(slope = beta1, intercept = beta0) + #BREAK
  geom_point(x=x0, y=beta0+beta1*x0, col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
```

`r chunk_reveal("reg_versiongraphique", break_type = "user", display_type="output")`

---


```{r reg_versiongraphique_M0}
ggplot(data=fake_dta) + 
  ylab('y') + xlim(range(fake_dta$x)) +ylim(range(fake_dta$y)) +
  ggtitle('Modèle nul') +
  geom_abline(slope = 0, intercept = mean(fake_dta$y)) + #BREAK
  geom_point(x=x0, y = mean(fake_dta$y), col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta0, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
```


`r chunk_reveal("reg_versiongraphique_M0", break_type = "user", display_type="output")`




```{r anova_versiongraphique_save, eval = TRUE}
pM0 <- ggplot(data=fake_dta) + 
  ylab('y') + xlim(range(fake_dta$x)) +ylim(range(fake_dta$y)) +
  ggtitle('Modèle nul') +
  geom_abline(slope = 0, intercept = mean(fake_dta$y)) + #BREAK
  geom_point(x=x0, y = mean(fake_dta$y), col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta0, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
pMcomp <- ggplot(data=fake_dta) + 
  ylab('y') + xlim(range(fake_dta$x)) +ylim(range(fake_dta$y)) +
  ggtitle('Modèle Mcomp') +
  geom_abline(slope = beta1, intercept = beta0) + #BREAK
  geom_point(x=x0, y=beta0+beta1*x0, col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
```


---
template: model

Lequel de ces mécanismes est le plus crédible au vu des donées ?

```{r compare_model_graph, eval = TRUE, echo = FALSE}
ggpubr::ggarrange(pMcomp, pM0, nrow = 1, common.legend = TRUE)
```

---
template: model

## Le modèle de régression simple 

$$Y_{k} = \beta_0 +\beta_1 x_{k}  +E_{k},\quad E_{k}\overset{ind}{\sim}\mathcal{N}(0, \sigma^2),$$
avec 
- $x_k$ la valeur de la variable explicative pour l'observation $k$, 
- $k=1,\ldots,n$ le numéro d'individu, $n$ le nombre total d'individus,
- $\beta_0$ l'ordonnée à l'origine, 
- $\beta_1$ la pente de la droite, mesure de l'effet de la variable $x$

- $\sigma^2$ la variance.

### Une écriture équivalente 

$$Y_{k} \overset{ind}{\sim}\mathcal{N}(\beta_0+\beta_1 x_k, \sigma^2).$$


### Nombre de paramètres du modèle

- $2$ paramètres de moyenne  $(\beta_0, \beta_1)$; 
- 1 paramètre de variance $\sigma^2$

---
template: model

## Le modèle de régression simple sur l'exemple de la pollution.

$$Y_{k} = \beta_0 +\beta_1 x_{k}  +E_{k},\quad E_{k}\overset{ind}{\sim}\mathcal{N}(0, \sigma^2),$$
avec 
- $x_k$ la population dans la ville $k$, 
- $k=1,\ldots,n$ le numéro de la ville, $n=41$,
- $\beta_0$ l'ordonnée à l'origine, 
- $\beta_1$ la pente de la droite, mesure de l'effet de la population sur la pollution.

- $\sigma^2$ la variance.

### Nombre de paramètres du modèle
- 2 paramètres de moyennes
- 1 paramètre de variance


---
template: model
## Sous forme matricielle
 $$\bf{Y = X\theta + E}$$
### Forme régulière 

$$Y=\begin{pmatrix}
Y_{1}\\
Y_{2}\\
\vdots\\
Y_{k}\\
\vdots\\
Y_{n}\end{pmatrix},
 \quad
{\bf{X}} =\overset{\color{gray}{\begin{matrix}\beta_0  & \beta_1\end{matrix}}}{\begin{pmatrix}
1 & x_1\\
1 & x_2\\
\vdots & \vdots\\
1 & x_k\\
 \vdots & \vdots\\
1 & x_n\\
 \end{pmatrix}},\quad
{\bf{\theta}} =\begin{pmatrix}
\beta_0\\
\beta_1\\
\end{pmatrix}, \quad{\bf{E}} = \overset{}{\begin{pmatrix}
E_{1}\\
E_{2}\\
\vdots\\
E_{k}\\
\vdots\\
E_{n}\\
\end{pmatrix}}$$
---
template: model

## Exercice

<p class=question> Détailler le modèle sous forme matricielle pour l'exemple de la pollution (écrire les 3 premières lignes de la matrice $X$ )</p>

--
Attention, la réponse est dans la slide qui suit !


---
template: model

## Correction 


```{r m_comp_false, eval = TRUE, echo = TRUE, out.width="100%"}
Mpop <- lm(SO2 ~ pop , data = usdata)
model.matrix(Mpop) %>% head(n = 3)
```
---
name: parametre
# Estimation des paramètres


---
template: parametre
## Estimation des paramètres du modèle version matricielle


Le modèle sous forme matricielle s'écrit

$$\bf{Y = X\theta + E}.$$
--

### Estimation de $\theta$

$$\hat{\theta} = (X^\intercal X )^{-1} X^\intercal Y_{obs}.$$

--

### Estimateur de $\theta$

$$T = (X^\intercal X )^{-1} X^\intercal Y.$$
--

### Loi de l'estimateur de $\theta$


$$T  \sim \mathcal{N}_{I}\left(\theta, \sigma^2 (X^\intercal X )^{-1}\right).$$

---
template: parametre
## Le paramètre de variance

La somme des carrés résiduelles s'écrit sous la forme 

$$RSS = || Y- X \hat{\theta} ||^2$$

### Estimateur de la variance 

  $$S^2 =\frac{1}{DF_{res}} RSS, $$
est un <a class=care> estimateur sans bias de  $\sigma^2$ </a> .

Dans le cas du modèle de régression simple  $DF_{res}=n-2$ (n observations et 2 paramètres de moyennes à estimer, le nombre de composantes dans le vecteur $\theta$)

--

## Estimation de $\sigma^2$

$$\hat{\sigma}^2 =\frac{1}{n-2} RSS_{obs}.$$
---
template: parametre
## Vérifier l'estimation sur l'exemple de la pollution


```{r estimation, eval = TRUE, echo = TRUE}
X <- model.matrix(Mpop)
XXprimemoinsUn <- solve(t(X)%*%X)
XXprimemoinsUn %*% t(X) %*% matrix(usdata$SO2, ncol =1)
summary(Mpop)$coefficients
```
--
## Loi de l'estimateur

```{r loi_estim,  eval = TRUE, echo = TRUE}
summary(Mpop)$sigma^2 * XXprimemoinsUn  # sigma2 Xt X
sqrt(diag(summary(Mpop)$sigma^2 * XXprimemoinsUn ))
```
---
name: prediction
# Prediction avec un modèle de régression simple
---
template:  prediction
Il est fréquent d'utiliser un modèle de régression pour prédire. 

## Prédiction de la valeur moyenne pour un $x$ particulier

### Valeur moyenne attendue pour $y$ pour un $x$ donné
$\beta_0+\beta_1 x.$

### Valeur moyenne prédite pour $y$ pour un $x$ donné
$\hat{\beta}_0+\hat{\beta}_1 x.$

```{r pred, eval = TRUE, echo = TRUE}
predict(Mpop, newdata=data.frame(pop=333))
```

### Intervalle de confiance pour la valeur moyenne prédite  pour $y$ pour un $x$ donné
$\hat{\beta}_0+\hat{\beta}_1 x.$

```{r pred_IC, eval = TRUE, echo = TRUE}
predict(Mpop, newdata=data.frame(pop=333), interval = 'confidence')
```

---
template:  prediction
Il est fréquent d'utiliser un modèle de régression pour prédire. 

## Prédiction de la valeur possible $y$ pour un  $x$ particulier

```{r pred_x, eval = TRUE, echo = TRUE}
predict(Mpop, newdata=data.frame(pop=333), interval = 'prediction')
```

---
template:  prediction
## Sur l'exemple de la polution

## Intervalle de confiance pour le comportement moyen


```{r predic_plot, eval = TRUE}
ggplot(usdata) + aes(x=pop, y= SO2 ) + geom_point() + geom_smooth(method= 'lm', se = TRUE)

```


---
count: false
template:  prediction
## Sur l'exemple de la polution

## Intervalle de confiance pour le comportement moyen


```{r predic_plot_pred, eval = TRUE}
pred_interval <- predict(Mpop,  interval="prediction", level = 0.95)
pred_interval <- as.data.frame(pred_interval) %>% mutate(pop=usdata$pop) %>% arrange(pop)

ggplot(usdata) + geom_point(aes(x=pop, y= SO2 ) )  + 
  geom_ribbon(data=pred_interval, aes(x = pop, ymin = lwr, ymax = upr), fill = "blue", alpha = 0.1) + geom_smooth(method= 'lm', se = TRUE, aes(x=pop, y= SO2 ) )
```

---
name: model
# Modèle de régression multiple

---
template: model

## Le modèle de régression multiple

Plusieurs variables sont potentiellement liées à la pollution en SO2


- temp : Average temperature in Fahrenheit
- manuf : No. of companies employing more than 20 employees
- pop : Population in thousands
- wind : Average annual wind speed in miles/hour
- precip : annual precipitation height in inches
- days : No. of days of precipitation


<a class=question> Quelles sont les variables liées à la pollution en SO2 ? </a>




---
template: model

## Le modèle de régression multiple 

$$Y_{k} = \beta_0 +\beta_1 x_{k}^{1}  + \beta_2 x_{k}^{2} + \ldots +  \beta_p x_{k}^{p}  +  E_{k},\quad E_{k}\overset{ind}{\sim}\mathcal{N}(0, \sigma^2),$$
avec 
- $x_{k}^{l}$ la valeur de la variable explicative $l$ pour l'observation $k$, 
- $k=1,\ldots,n$ le numéro d'individu, $n$ le nombre total d'individus,
- $\beta_0$ l'ordonnée à l'origine, 
- $\beta_l$ l'effet de la variable $X^{l}$ sur la variable à expliquer,
- $\sigma^2$ la variance.

### Une écriture équivalente 

$$Y_{k} \overset{ind}{\sim}\mathcal{N}(\beta_0 +\beta_1 x_{k}^{1}  + \beta_2 x_{k}^{2} + \ldots +  \beta_p x_{k}^{p} , \sigma^2).$$


### Nombre de paramètres du modèle

- $l+1$ paramètres de moyenne  $(\beta_0, \beta_1, \ldots, \beta_l)$; 
- 1 paramètre de variance $\sigma^2$

---
template: model
## Sous forme matricielle
 $$\bf{Y = X\theta + E}$$
### Forme régulière 

$$Y=\begin{pmatrix}
Y_{1}\\
Y_{2}\\
\vdots\\
Y_{k}\\
\vdots\\
Y_{n}\end{pmatrix},
 \quad
{\bf{X}} =\overset{\color{gray}{\begin{matrix}\beta_0  && \beta_1&& \beta_2&&\ldots &&\beta_l\end{matrix}}}{\begin{pmatrix}
1 & x_1^{1} & x_1^{2} & \ldots &x_1^{l}\\
1 & x_2^{1} & x_2^{2} & \ldots &x_2^{l}\\
\vdots & \vdots& \vdots && \vdots\\
1 & x_k^{1} & x_k^{2} & \ldots &x_k^{l}\\
 \vdots & \vdots& \vdots && \vdots\\
1 & x_n^{1} & x_n^{2} & \ldots &x_n^{l}\\
 \end{pmatrix}},\quad
{\bf{\theta}} =\begin{pmatrix}
\beta_0\\
\beta_1\\
\beta_2\\
\vdots\\
\beta_l\\
\end{pmatrix}, \quad{\bf{E}} = \overset{}{\begin{pmatrix}
E_{1}\\
E_{2}\\
\vdots\\
E_{k}\\
\vdots\\
E_{n}\\
\end{pmatrix}}$$

---
template: model

## Sur l'exemple de la pollution


```{r m_comp_mult, eval = TRUE, echo = TRUE, out.width="100%"}
Mcomp <- lm(SO2 ~ temp + manuf + pop + wind + precip + days, data = usdata) 
#Mcomp <- lm(SO2 ~ . - City , data = usdata) # toutes les variables sauf City
model.matrix(Mcomp) %>% head(n = 3)
```
---
name: parametre
# Estimation des paramètres


---
template: parametre
## Estimation des paramètres du modèle version matricielle


Le modèle sous forme matricielle s'écrit

$$\bf{Y = X\theta + E}.$$
--

### Estimation de $\theta$

$$\hat{\theta} = (X^\intercal X )^{-1} X^\intercal Y_{obs}.$$

--

### Estimateur de $\theta$

$$T = (X^\intercal X )^{-1} X^\intercal Y.$$
--

### Loi de l'estimateur de $\theta$


$$T  \sim \mathcal{N}_{I}\left(\theta, \sigma^2 (X^\intercal X )^{-1}\right).$$

---
template: parametre
## Le paramètre de variance

La somme des carrés résiduelles s'écrit sous la forme 

$$RSS = || Y- X \hat{\theta} ||^2$$

### Estimateur de la variance 

  $$S^2 =\frac{1}{DF_{res}} RSS, $$
est un <a class=care> estimateur sans bias de  $\sigma^2$ </a> .

Dans le cas du modèle de régression simple  $DF_{res}=n-l-1$ (n observations et 2 paramètres de moyennes à estimer, le nombre de composantes dans le vecteur $\theta$)

--

## Estimation de $\sigma^2$

$$\hat{\sigma}^2 =\frac{1}{n-l-1} RSS_{obs}.$$
---
template: parametre
## Vérifier l'estimation sur l'exemple de la pollution

### Estimation

```{r estimation_mult, eval = TRUE, echo = TRUE}
X <- model.matrix(Mcomp)
XXprimemoinsUn <- solve(t(X)%*%X)
XXprimemoinsUn %*% t(X) %*% matrix(usdata$SO2, ncol =1)
summary(Mcomp)$coefficients
```
---

template: parametre
## Vérifier l'estimation sur l'exemple de la pollution

### Loi de l'estimateur

```{r loi_estim_mult,  eval = TRUE, echo = TRUE}
summary(Mcomp)$coefficients
sqrt(diag(summary(Mcomp)$sigma^2 * XXprimemoinsUn ))
```


---
name: modcomp
# Test du modèle complet


---
template: modcomp
## Pollution 

<p class="question"> La pollution en SO2 dans les villes américaines est elles liées à l'une au moins des variables caractérisiques des villes ?</p>


--

On va à la pêche ....

---
template: modcomp
## Sous forme de comparaison de modèle


```{r compare_model_graph2, ref.label='compare_model_graph', eval = TRUE, echo = FALSE, results='markup'}
```

--
<p class="question"> Le modèle Mcomp est il plus pertinent que le modèle M0 ?</p>



---
template: modcomp
## Hypothèses du test

On va donc opposer une hypothèse de travail $H_0$ contre une hypothèse alternative $H_1$. $H_0$ peut donc prendre différentes formes:


$$\begin{align} 
H_0 & =\left \lbrace \mbox{Auncune variable n'est liée à la pollution en SO2}\right\rbrace\\
    & =\left \lbrace  \mbox{pour tout }p\geq 1, \beta_p =0   \right\rbrace\\
    & =\left \lbrace  M_{comp} \mbox{ est équivalent à } M0 \right\rbrace.
\end{align}$$


$H_1$ prend les formes équivalentes suivantes

$$\begin{align} 
H_1 & =\left \lbrace \mbox{Au moins 1 variable est liée à la pollution en SO2}\right\rbrace\\
    & =\left \lbrace  \mbox{Il existe un } p, \beta_p \ne 0  \right\rbrace\\
    & =\left \lbrace  M_{comp} \mbox{ est préférable à } M0 \right\rbrace.
\end{align}$$

--

Sous $H_0$, 
$$F= \frac{\frac{SS_{M_{comp}}}{l}}{\frac{RSS}{n-l-1}} \underset{H_0}{\sim}\mathcal{F}(l, n-l-1)$$  

---
template: modcomp
## Loi de la statistique de test sous $H_0$ - graphiquement

Sous $H_0$ la loi de distribution de $F$ est 

```{r p_value, eval = TRUE}
tibble(x = seq(0, 10, length.out = 2001)) %>% 
  mutate(y = df(x, df1 = 4, df= 38)) -> chi_dta
Fobs <- 1
chi_dta %>% filter(x> Fobs) %>% add_row(x=100,y = 0) %>%  add_row(x=Fobs, y =0)  %>% 
  add_row(x=Fobs, y =df(Fobs, df1 = 4, df= 38)) %>% arrange(x,y)  -> chi_dta_poly
```


```{r pvalue_graphique}
ggplot(data  = chi_dta) + xlab('y') + ylab('density') + geom_line(aes(x=x, y=y)) + #BREAK
  annotate("text", x = Fobs- 0.5, y = 0.05, label = "Fobs", col = 'red')+  geom_vline(aes(xintercept = Fobs), col = 'red') + #BREAK
  geom_polygon(data = chi_dta_poly,  aes(x=x, y= y), alpha = 0.3) + xlim(c(0, max(chi_dta$x))) 

```

---

`r chunk_reveal("pvalue_graphique", break_type = "user", display_type="output")`

---
name: test_variable
# Test de l'effet des variables

---
template: test_variable

## Test sur les paramètres

Tester la nullité du paramètre $\beta_l$ revient à tester si la variable $x^{l}$ et la variable $Y$ sont liées.


--

Ce test est similaire  au test de comparaison entre le modèle complet et le modèle complet privé de la variable $x^{l}$.


---
count: false
template: test_variable

## Equivalence des tests sur l'exemple de la pollution


```{r car, echo=FALSE, eval=TRUE}
library(car)
```

```{r pol_mult, eval = TRUE}
summary(Mcomp)$coefficients
Mcomp_l <- lm(SO2 ~  temp + manuf +  wind + precip + days, data = usdata) 
anova(Mcomp_l, Mcomp)
```

### Lien entre les statistiques  de tests

```{r stu2, eval = TRUE, echo =TRUE}
res <- summary(Mcomp)$coefficients
res[,"t value"]^2
```

---
template: test_variable
## Vigilance sur l'interprétation des tests


```{r test_inter, eval =TRUE}
summary(Mcomp)$coefficients
```

--
```{r ggpairs, eval = TRUE}
GGally::ggpairs(usdata, columns = 2:8)
```

---
#Diagnostics

```{r diag, eval = TRUE, echo = TRUE, out.width='70%', cache = FALSE}
library(ggfortify)
autoplot(Mcomp)
```


---
# Levier

## Mathématiquement

Le levier $lev_i$ pour l'observation $i$ est défini par
$$H=X (X^\intercal X)^{-1}X^\intercal; \quad lev_{i}= H_{ii},$$
--
### D'où viennt cette matrice $H$ ?

$$ \hat{Y} = H Y$$
--
### Sur l'exemple de la régression simple 

```{r levier}, eval = TRUE, echo = TRUE}
h.us.lm <- hatvalues(Mpop)
h.us.lm
```

---

```{r levier1}

usdata <- usdata %>% mutate(grand = as.factor(ifelse(pop > 2500, 'g', 'p')))
usdata_sans_chicago <- usdata %>% filter(pop < 2500)

usdata %>% ggplot() + aes(x=pop, y=SO2) + geom_point(aes(col = grand)) + theme(legend.position = 'none') + geom_smooth(method= 'lm', se = FALSE,col= "#FF0000") + #BREAK
  geom_smooth(data=usdata_sans_chicago, aes(x=pop, y=SO2), method= 'lm', se = FALSE,col= "#00A08A")

```


`r chunk_reveal("levier1", break_type = "user", display_type="output")`


---
# Construire le modèle d'analyse de la covariance

## A partir des données chauve souris (bats)

Les différentes espèces de chauve souris ont des tailles de cerveau très variables, ce qui conduit à des volumes variables de la partie auditive.

Quel modèle pouvez vous proposer pour étudier l’influence du régime sur la part du cerveau dédiée à l’audition, compte tenu de la taille total du cerveau ? 

Quel test pourrait permettre d’étudier cette influence ?




---
# Pause

<br><br><br><br>
<p style="color:#B40F20;font-size:35px;text-align:center;">Prenons une petite pause !!!

Correction en TP </p> 



```{r ggplot_back, echo = FALSE, eval = TRUE}
ggplot <- function(...) ggplot2::ggplot(...) 
```

